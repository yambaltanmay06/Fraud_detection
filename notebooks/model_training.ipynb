{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d15311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Preprocessed Data\n",
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fbaa1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Initialize Models\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "rf_model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da50b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg_model.fit(X_train, y_train)\n",
    "logreg_train_pred = logreg_model.predict(X_train)  \n",
    "logreg_test_pred = logreg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f991e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_train_pred = rf_model.predict(X_train)         \n",
    "rf_test_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5430a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "Training Accuracy: 0.9598091025798849\n",
      "Testing Accuracy: 0.9594639748166646\n",
      "Classification Report (Test Data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     56750\n",
      "           1       0.98      0.94      0.96     56976\n",
      "\n",
      "    accuracy                           0.96    113726\n",
      "   macro avg       0.96      0.96      0.96    113726\n",
      "weighted avg       0.96      0.96      0.96    113726\n",
      "\n",
      "Confusion Matrix (Test Data):\n",
      " [[55727  1023]\n",
      " [ 3587 53389]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Metrics\n",
    "print(\"\\nLogistic Regression Model Evaluation:\")\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, logreg_train_pred))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, logreg_test_pred))\n",
    "print(\"Classification Report (Test Data):\\n\", classification_report(y_test, logreg_test_pred))\n",
    "print(\"Confusion Matrix (Test Data):\\n\", confusion_matrix(y_test, logreg_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "111e547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Model Evaluation:\n",
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.9998856901675958\n",
      "Classification Report (Test Data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56750\n",
      "           1       1.00      1.00      1.00     56976\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n",
      "Confusion Matrix (Test Data):\n",
      " [[56737    13]\n",
      " [    0 56976]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Metrics\n",
    "print(\"\\nRandom Forest Model Evaluation:\")\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, rf_train_pred))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, rf_test_pred))\n",
    "print(\"Classification Report (Test Data):\\n\", classification_report(y_test, rf_test_pred))\n",
    "print(\"Confusion Matrix (Test Data):\\n\", confusion_matrix(y_test, rf_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bba4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ba2f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# 2. Save the Trained Models\n",
    "\n",
    "# Save Logistic Regression model\n",
    "joblib.dump(logreg_model, 'logistic_regression_model.pkl')\n",
    "\n",
    "# Save Random Forest model\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "\n",
    "print(\"âœ… Models saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4aa75ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = joblib.load('logistic_regression_model.pkl')\n",
    "rf_model = joblib.load('random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97213e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Compare Model Performances\n",
    "\n",
    "# Logistic Regression\n",
    "logreg_pred = logreg_model.predict(X_test)\n",
    "logreg_acc = accuracy_score(y_test, logreg_pred)\n",
    "\n",
    "# Random Forest\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91c6f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest'],\n",
    "    'Testing Accuracy': [logreg_acc, rf_acc]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "effbb478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Model Comparison Table:\n",
      "                 Model  Testing Accuracy\n",
      "0  Logistic Regression          0.959464\n",
      "1        Random Forest          0.999886\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ“Š Model Comparison Table:\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c4b3af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Model Comparison Report saved as 'model_comparison_report.csv'!\n"
     ]
    }
   ],
   "source": [
    "# 4. Save the Comparison Table\n",
    "comparison_df.to_csv('model_comparison_report.csv', index=False)\n",
    "print(\"\\nâœ… Model Comparison Report saved as 'model_comparison_report.csv'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6788e054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nProject Structure:\\n\\nyour_project_folder/\\nâ”œâ”€â”€ data/\\nâ”‚   â”œâ”€â”€ your_dataset.csv\\nâ”œâ”€â”€ models/\\nâ”‚   â”œâ”€â”€ logistic_regression_model.pkl\\nâ”‚   â”œâ”€â”€ random_forest_model.pkl\\nâ”œâ”€â”€ notebooks/\\nâ”‚   â”œâ”€â”€ eda.ipynb\\nâ”‚   â”œâ”€â”€ data_preprocessing.ipynb\\nâ”‚   â”œâ”€â”€ model_training.ipynb\\nâ”œâ”€â”€ reports/\\nâ”‚   â””â”€â”€ model_comparison_report.csv\\nâ”œâ”€â”€ README.md \\nâ””â”€â”€ requirements.txt\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Project Structure:\n",
    "\n",
    "your_project_folder/\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ your_dataset.csv\n",
    "â”œâ”€â”€ models/\n",
    "â”‚   â”œâ”€â”€ logistic_regression_model.pkl\n",
    "â”‚   â”œâ”€â”€ random_forest_model.pkl\n",
    "â”œâ”€â”€ notebooks/\n",
    "â”‚   â”œâ”€â”€ eda.ipynb\n",
    "â”‚   â”œâ”€â”€ data_preprocessing.ipynb\n",
    "â”‚   â”œâ”€â”€ model_training.ipynb\n",
    "â”œâ”€â”€ reports/\n",
    "â”‚   â””â”€â”€ model_comparison_report.csv\n",
    "â”œâ”€â”€ README.md \n",
    "â””â”€â”€ requirements.txt\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
